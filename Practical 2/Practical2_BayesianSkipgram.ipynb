{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# read in data, remove punctuation and make all lower case\n",
    "def read_corpus(filename):\n",
    "    corpus = []\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    with open(filename) as f:\n",
    "        for s in f:\n",
    "            clean_s = s.translate(translator).lower()\n",
    "            clean_words = clean_s.split()\n",
    "            corpus.append(clean_words)\n",
    "    return corpus\n",
    "\n",
    "#Make data dictionaries and indexing \n",
    "def make_dictionaries(corpus):\n",
    "    # create one set of all unique words\n",
    "    flat_corpus = [w for s in corpus for w in s]\n",
    "    corpus_set = set(flat_corpus)\n",
    "    w_to_i = {}\n",
    "    i_to_w = {}\n",
    "    w_freq = []\n",
    "    num_words = len(corpus_set)\n",
    "    for i, w in enumerate(corpus_set):\n",
    "        w_to_i[w] = i\n",
    "        i_to_w[i] = w\n",
    "        freq = flat_corpus.count(w)   \n",
    "        w_freq.append([i, freq])\n",
    "    return w_to_i, i_to_w, np.array(w_freq), num_words\n",
    "\n",
    "def make_word_windows(corpus, window_size):\n",
    "    windows = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        for i, word in enumerate(sentence):\n",
    "            curr_window = np.zeros(shape=[5])\n",
    "            \n",
    "            #Check if index allows large enough window sampling\n",
    "            if (i - WINDOW_SIZE > 0) and (i+ WINDOW_SIZE < len(sentence)):\n",
    "                word_index = w_to_i[word]\n",
    "                curr_window[0] = word_index\n",
    "                n=1\n",
    "                for j in range(i-WINDOW_SIZE, i+WINDOW_SIZE):\n",
    "                    context_index=w_to_i[sentence[j]]\n",
    "                    curr_window[n:] = context_index\n",
    "                    n+=1\n",
    "                windows.append(torch.LongTensor(curr_window))\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 2\n",
    "EMBEDDING_DIM = 128\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOME DECISIONS TO MAKE HERE BEFORE RUNNING WITH LARGE CORPUS: \n",
    "### 1st: Word window\n",
    "### 2nd: What to do when sentence is smaller than window size? Disregard? Fill with 0s? \n",
    "### If the above, fix vocab index for -UNK-\n",
    "### For now only keeping windows if sentences are large enough\n",
    "\n",
    "\n",
    "corpus = read_corpus('wa/test.en')\n",
    "w_to_i, i_to_w, w_freq, num_words = make_dictionaries(corpus)\n",
    "data = make_word_windows(corpus, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import distributions\n",
    "\n",
    "class bayesian_skipgram(nn.Module):\n",
    "    def __init__(self, num_words, emb_dim):\n",
    "        super(bayesian_skipgram, self).__init__()\n",
    "\n",
    "        self.num_words = num_words\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.R = nn.Embedding(num_words, emb_dim)\n",
    "        self.mu_prior = nn.Embedding(num_words, emb_dim)\n",
    "        self.sigma_prior  = nn.Embedding(num_words, emb_dim)\n",
    "        \n",
    "        self.M = nn.Linear(2*emb_dim, 2*emb_dim)\n",
    "        self.affine_lambda_mu = nn.Linear(2*emb_dim, emb_dim)\n",
    "        self.affine_lambda_sigma = nn.Linear(2*emb_dim, emb_dim)\n",
    "        self.affine_theta = nn.Linear(emb_dim, num_words)\n",
    "        \n",
    "\n",
    "    def forward(self, word_idx, context_idx):\n",
    "        \n",
    "        batch_size = word_idx.shape[0]\n",
    "        n_context = len(context_idx[0])\n",
    "        \n",
    "        # ********** Encoder ************\n",
    "        \n",
    "        R_w = self.R(word_idx) \n",
    "        R_w = R_w.view(batch_size, 1, self.emb_dim) \n",
    "        R_w = R_w.repeat(1, n_context, 1) \n",
    "        \n",
    "        R_cj = self.R(context_idx)\n",
    "        \n",
    "        \n",
    "        RcRw = torch.cat((R_w, R_cj), dim=2)\n",
    "    \n",
    "        h = nn.ReLU()(self.M(RcRw)) \n",
    "        h = torch.sum(h, dim=1)   \n",
    "\n",
    "        mu = self.affine_lambda_mu(h)\n",
    "        sigma = nn.functional.softplus(self.affine_lambda_sigma(h))\n",
    "\n",
    "        # reparametrization trick\n",
    "        eps = distributions.MultivariateNormal(torch.zeros(self.emb_dim), torch.eye(self.emb_dim)).sample()\n",
    "        z = mu + sigma * eps    \n",
    "               \n",
    "            \n",
    "        # ********* Decoder ***********\n",
    "    \n",
    "        affine_categ = self.affine_theta(z)\n",
    "        f_i = nn.functional.softmax(affine_categ, dim=1)    \n",
    "                            \n",
    "        mu_prior = self.mu_prior(word_idx)\n",
    "        sigma_prior = nn.functional.softplus(self.sigma_prior(word_idx))\n",
    "            \n",
    "        # ********** Loss ************\n",
    "        \n",
    "        likelihood_terms = torch.zeros(batch_size)\n",
    "        KL_div_terms = torch.zeros(batch_size)\n",
    "        \n",
    "        for i, contexts in enumerate(context_idx):  \n",
    "            likelihood = 0\n",
    "            for idx in contexts:\n",
    "                likelihood += torch.log(f_i[i, idx] +1e-8)\n",
    "            likelihood_terms[i] = likelihood\n",
    "            \n",
    "            KL =  self.KL_div(mu_prior[i], sigma_prior[i],  mu[i],  sigma[i] )\n",
    "            KL_div_terms[i] = KL\n",
    "            \n",
    "          \n",
    "        total_loss = torch.mean(KL_div_terms) - torch.mean(likelihood_terms)\n",
    "             \n",
    "        return total_loss\n",
    "    \n",
    "    def KL_div(self,  mu_p, sigma_p, mu, sigma):\n",
    "        div = torch.log(sigma_p + 1e-8) - torch.log(sigma+1e-8) + (sigma**2 + (mu - mu_p)**2) / (2*sigma_p**2) - 0.5\n",
    "        return div.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch  0\n",
      "0.05086541175842285\n",
      "tensor(1571.4757)\n",
      "at batch  10\n",
      "0.4946765899658203\n",
      "tensor(813.2048)\n",
      "at batch  20\n",
      "0.5046517848968506\n",
      "tensor(565.2198)\n",
      "at batch  30\n",
      "0.4866976737976074\n",
      "tensor(752.6623)\n",
      "at batch  40\n",
      "0.4857015609741211\n",
      "tensor(754.9451)\n",
      "at batch  50\n",
      "0.4757273197174072\n",
      "tensor(540.2704)\n",
      "at batch  60\n",
      "0.4876983165740967\n",
      "tensor(428.0025)\n",
      "at batch  0\n",
      "0.21642136573791504\n",
      "tensor(758.2332)\n",
      "at batch  10\n",
      "0.6113681793212891\n",
      "tensor(335.9749)\n",
      "at batch  20\n",
      "0.4986698627471924\n",
      "tensor(322.9376)\n",
      "at batch  30\n",
      "0.4797170162200928\n",
      "tensor(599.7666)\n",
      "at batch  40\n",
      "0.4687464237213135\n",
      "tensor(328.2284)\n",
      "at batch  50\n",
      "0.5176165103912354\n",
      "tensor(404.6554)\n",
      "at batch  60\n",
      "0.6363000869750977\n",
      "tensor(478.3223)\n",
      "at batch  0\n",
      "0.26927900314331055\n",
      "tensor(334.6642)\n",
      "at batch  10\n",
      "0.4797196388244629\n",
      "tensor(675.4565)\n",
      "at batch  20\n",
      "0.48470401763916016\n",
      "tensor(261.9224)\n",
      "at batch  30\n",
      "0.5634973049163818\n",
      "tensor(24793.6055)\n",
      "at batch  40\n",
      "0.4976680278778076\n",
      "tensor(230.3930)\n",
      "at batch  50\n",
      "0.4777224063873291\n",
      "tensor(367.0016)\n",
      "at batch  60\n",
      "0.5754623413085938\n",
      "tensor(265.8740)\n",
      "at batch  0\n",
      "0.22041583061218262\n",
      "tensor(231.7680)\n",
      "at batch  10\n",
      "0.5904140472412109\n",
      "tensor(243.2642)\n",
      "at batch  20\n",
      "0.5345711708068848\n",
      "tensor(223.8539)\n",
      "at batch  30\n",
      "0.4916863441467285\n",
      "tensor(278.4502)\n",
      "at batch  40\n",
      "0.4747300148010254\n",
      "tensor(250.7744)\n",
      "at batch  50\n",
      "0.4747314453125\n",
      "tensor(217.9521)\n",
      "at batch  60\n",
      "0.5884296894073486\n",
      "tensor(229.7666)\n",
      "at batch  0\n",
      "0.3450794219970703\n",
      "tensor(183.0767)\n",
      "at batch  10\n",
      "0.6173496246337891\n",
      "tensor(167.4150)\n",
      "at batch  20\n",
      "0.4906888008117676\n",
      "tensor(188.0148)\n",
      "at batch  30\n",
      "0.5066454410552979\n",
      "tensor(217.0931)\n",
      "at batch  40\n",
      "0.5016636848449707\n",
      "tensor(180.5302)\n",
      "at batch  50\n",
      "0.493680477142334\n",
      "tensor(182.1899)\n",
      "at batch  60\n",
      "0.552523136138916\n",
      "tensor(181.1131)\n",
      "at batch  0\n",
      "0.23636984825134277\n",
      "tensor(144.4757)\n",
      "at batch  10\n",
      "0.4966716766357422\n",
      "tensor(151.2418)\n",
      "at batch  20\n",
      "0.4936797618865967\n",
      "tensor(159.8485)\n",
      "at batch  30\n",
      "0.48470520973205566\n",
      "tensor(150.4768)\n",
      "at batch  40\n",
      "0.4637641906738281\n",
      "tensor(153.9445)\n",
      "at batch  50\n",
      "0.49866700172424316\n",
      "tensor(177.9554)\n",
      "at batch  60\n",
      "0.5325753688812256\n",
      "tensor(173.9631)\n",
      "at batch  0\n",
      "0.25831031799316406\n",
      "tensor(108.0551)\n",
      "at batch  10\n",
      "0.5226049423217773\n",
      "tensor(133.2388)\n",
      "at batch  20\n",
      "0.5255916118621826\n",
      "tensor(128.1046)\n",
      "at batch  30\n",
      "0.5006616115570068\n",
      "tensor(132.1083)\n",
      "at batch  40\n",
      "0.4916865825653076\n",
      "tensor(122.4150)\n",
      "at batch  50\n",
      "0.5186140537261963\n",
      "tensor(153.2197)\n",
      "at batch  60\n",
      "0.5455410480499268\n",
      "tensor(120.7581)\n",
      "at batch  0\n",
      "0.26628947257995605\n",
      "tensor(101.6804)\n",
      "at batch  10\n",
      "0.5236003398895264\n",
      "tensor(145.1136)\n",
      "at batch  20\n",
      "0.5086438655853271\n",
      "tensor(122.7044)\n",
      "at batch  30\n",
      "0.513629674911499\n",
      "tensor(111.6430)\n",
      "at batch  40\n",
      "0.5076441764831543\n",
      "tensor(105.6348)\n",
      "at batch  50\n",
      "0.5226025581359863\n",
      "tensor(97.7429)\n",
      "at batch  60\n",
      "0.5186140537261963\n",
      "tensor(103.5358)\n",
      "at batch  0\n",
      "0.2403576374053955\n",
      "tensor(93.5909)\n",
      "at batch  10\n",
      "0.5136289596557617\n",
      "tensor(105.4349)\n",
      "at batch  20\n",
      "0.49567580223083496\n",
      "tensor(84.3440)\n",
      "at batch  30\n",
      "0.49567556381225586\n",
      "tensor(79.4921)\n",
      "at batch  40\n",
      "0.5136282444000244\n",
      "tensor(92.3657)\n",
      "at batch  50\n",
      "0.5196118354797363\n",
      "tensor(124.7091)\n",
      "at batch  60\n",
      "0.5076439380645752\n",
      "tensor(97.1405)\n",
      "at batch  0\n",
      "0.21941304206848145\n",
      "tensor(100.7612)\n",
      "at batch  10\n",
      "0.5126283168792725\n",
      "tensor(86.1704)\n",
      "at batch  20\n",
      "0.4727363586425781\n",
      "tensor(90.1279)\n",
      "at batch  30\n",
      "0.5156219005584717\n",
      "tensor(90.4762)\n",
      "at batch  40\n",
      "0.4777228832244873\n",
      "tensor(86.6537)\n",
      "at batch  50\n",
      "0.4946773052215576\n",
      "tensor(87.3314)\n",
      "at batch  60\n",
      "0.4976694583892822\n",
      "tensor(104.9052)\n",
      "at batch  0\n",
      "0.24335074424743652\n",
      "tensor(88.7226)\n",
      "at batch  10\n",
      "0.49167823791503906\n",
      "tensor(92.2879)\n",
      "at batch  20\n",
      "0.4986691474914551\n",
      "tensor(78.8367)\n",
      "at batch  30\n",
      "0.49866747856140137\n",
      "tensor(83.7880)\n",
      "at batch  40\n",
      "0.49767088890075684\n",
      "tensor(85.5942)\n",
      "at batch  50\n",
      "0.48470520973205566\n",
      "tensor(92.8409)\n",
      "at batch  60\n",
      "0.6742022037506104\n",
      "tensor(78.0351)\n",
      "at batch  0\n",
      "0.2214035987854004\n",
      "tensor(80.5335)\n",
      "at batch  10\n",
      "0.6263275146484375\n",
      "tensor(83.5470)\n",
      "at batch  20\n",
      "0.6203415393829346\n",
      "tensor(66.2063)\n",
      "at batch  30\n",
      "0.583439826965332\n",
      "tensor(83.9159)\n",
      "at batch  40\n",
      "0.5435473918914795\n",
      "tensor(70.0851)\n",
      "at batch  50\n",
      "0.6103682518005371\n",
      "tensor(73.2067)\n",
      "at batch  60\n",
      "0.6303157806396484\n",
      "tensor(79.3795)\n",
      "at batch  0\n",
      "0.2623002529144287\n",
      "tensor(71.6122)\n",
      "at batch  10\n",
      "0.5714733600616455\n",
      "tensor(68.3043)\n",
      "at batch  20\n",
      "0.563493013381958\n",
      "tensor(64.9937)\n",
      "at batch  30\n",
      "0.7031214237213135\n",
      "tensor(57.5578)\n",
      "at batch  40\n",
      "0.5226023197174072\n",
      "tensor(69.9013)\n",
      "at batch  50\n",
      "0.5335710048675537\n",
      "tensor(67.0874)\n",
      "at batch  60\n",
      "0.5545165538787842\n",
      "tensor(76.8448)\n",
      "at batch  0\n",
      "0.2144317626953125\n",
      "tensor(55.7375)\n",
      "at batch  10\n",
      "0.5016591548919678\n",
      "tensor(73.4767)\n",
      "at batch  20\n",
      "0.5654892921447754\n",
      "tensor(77.3997)\n",
      "at batch  30\n",
      "0.586432695388794\n",
      "tensor(61.5721)\n",
      "at batch  40\n",
      "0.5026588439941406\n",
      "tensor(69.1154)\n",
      "at batch  50\n",
      "0.4916865825653076\n",
      "tensor(52.1891)\n",
      "at batch  60\n",
      "0.48171186447143555\n",
      "tensor(72.5941)\n",
      "at batch  0\n",
      "0.23237967491149902\n",
      "tensor(57.6903)\n",
      "at batch  10\n",
      "0.4966719150543213\n",
      "tensor(66.9206)\n",
      "at batch  20\n",
      "0.4797172546386719\n",
      "tensor(59.7437)\n",
      "at batch  30\n",
      "0.4777238368988037\n",
      "tensor(60.8278)\n",
      "at batch  40\n",
      "0.4797179698944092\n",
      "tensor(58.0259)\n",
      "at batch  50\n",
      "0.48470354080200195\n",
      "tensor(62.3095)\n",
      "at batch  60\n",
      "0.46875786781311035\n",
      "tensor(62.4403)\n",
      "at batch  0\n",
      "0.23636865615844727\n",
      "tensor(53.8739)\n",
      "at batch  10\n",
      "0.48769474029541016\n",
      "tensor(62.6095)\n",
      "at batch  20\n",
      "0.48670077323913574\n",
      "tensor(43.2747)\n",
      "at batch  30\n",
      "0.47872018814086914\n",
      "tensor(55.3424)\n",
      "at batch  40\n",
      "0.4916856288909912\n",
      "tensor(73.3884)\n",
      "at batch  50\n",
      "0.5106346607208252\n",
      "tensor(65.2287)\n",
      "at batch  60\n",
      "0.4847071170806885\n",
      "tensor(59.4679)\n",
      "at batch  0\n",
      "0.2403576374053955\n",
      "tensor(57.2849)\n",
      "at batch  10\n",
      "0.6741974353790283\n",
      "tensor(47.6622)\n",
      "at batch  20\n",
      "0.6732008457183838\n",
      "tensor(55.3746)\n",
      "at batch  30\n",
      "0.594414234161377\n",
      "tensor(54.0832)\n",
      "at batch  40\n",
      "0.5196108818054199\n",
      "tensor(50.8275)\n",
      "at batch  50\n",
      "0.49667930603027344\n",
      "tensor(58.8149)\n",
      "at batch  60\n",
      "0.5046508312225342\n",
      "tensor(61.8410)\n",
      "at batch  0\n",
      "0.22440171241760254\n",
      "tensor(56.6766)\n",
      "at batch  10\n",
      "0.4856991767883301\n",
      "tensor(54.4140)\n",
      "at batch  20\n",
      "0.493680477142334\n",
      "tensor(47.6652)\n",
      "at batch  30\n",
      "0.645277738571167\n",
      "tensor(43.4362)\n",
      "at batch  40\n",
      "0.506648063659668\n",
      "tensor(72.4988)\n",
      "at batch  50\n",
      "0.4886951446533203\n",
      "tensor(56.6634)\n",
      "at batch  60\n",
      "0.5605018138885498\n",
      "tensor(48.7149)\n",
      "at batch  0\n",
      "0.2682836055755615\n",
      "tensor(51.1152)\n",
      "at batch  10\n",
      "0.5844376087188721\n",
      "tensor(46.8496)\n",
      "at batch  20\n",
      "0.4807157516479492\n",
      "tensor(45.4866)\n",
      "at batch  30\n",
      "0.5026576519012451\n",
      "tensor(60.3475)\n",
      "at batch  40\n",
      "0.6372973918914795\n",
      "tensor(54.8473)\n",
      "at batch  50\n",
      "0.5066409111022949\n",
      "tensor(53.3006)\n",
      "at batch  60\n",
      "0.4946777820587158\n",
      "tensor(48.8499)\n",
      "at batch  0\n",
      "0.23237943649291992\n",
      "tensor(39.4838)\n",
      "at batch  10\n",
      "0.5794503688812256\n",
      "tensor(40.0046)\n",
      "at batch  20\n",
      "0.5934162139892578\n",
      "tensor(38.5261)\n",
      "at batch  30\n",
      "0.5804526805877686\n",
      "tensor(48.7479)\n",
      "at batch  40\n",
      "0.46475744247436523\n",
      "tensor(49.8247)\n",
      "at batch  50\n",
      "0.4807157516479492\n",
      "tensor(54.8601)\n",
      "at batch  60\n",
      "0.47872018814086914\n",
      "tensor(48.6784)\n",
      "at batch  0\n",
      "0.21442747116088867\n",
      "tensor(52.0589)\n",
      "at batch  10\n",
      "0.6353013515472412\n",
      "tensor(55.7567)\n",
      "at batch  20\n",
      "0.505648136138916\n",
      "tensor(43.7416)\n",
      "at batch  30\n",
      "0.4946722984313965\n",
      "tensor(48.0553)\n",
      "at batch  40\n",
      "0.482708215713501\n",
      "tensor(40.2802)\n",
      "at batch  50\n",
      "0.4916877746582031\n",
      "tensor(39.9011)\n",
      "at batch  60\n",
      "0.6353082656860352\n",
      "tensor(43.7901)\n",
      "at batch  0\n",
      "0.22739362716674805\n",
      "tensor(45.7215)\n",
      "at batch  10\n",
      "0.4966740608215332\n",
      "tensor(46.2019)\n",
      "at batch  20\n",
      "0.4946751594543457\n",
      "tensor(44.3717)\n",
      "at batch  30\n",
      "0.6173505783081055\n",
      "tensor(42.9240)\n",
      "at batch  40\n",
      "0.5255951881408691\n",
      "tensor(49.1846)\n",
      "at batch  50\n",
      "0.48171281814575195\n",
      "tensor(34.8818)\n",
      "at batch  60\n",
      "0.4827086925506592\n",
      "tensor(42.1132)\n",
      "at batch  0\n",
      "0.22639822959899902\n",
      "tensor(33.4723)\n",
      "at batch  10\n",
      "0.4637565612792969\n",
      "tensor(34.6892)\n",
      "at batch  20\n",
      "0.471743106842041\n",
      "tensor(48.6050)\n",
      "at batch  30\n",
      "0.47872042655944824\n",
      "tensor(38.8245)\n",
      "at batch  40\n",
      "0.4886939525604248\n",
      "tensor(43.1135)\n",
      "at batch  50\n",
      "0.4687473773956299\n",
      "tensor(34.6682)\n",
      "at batch  60\n",
      "0.5993978977203369\n",
      "tensor(36.9478)\n",
      "at batch  0\n",
      "0.31316280364990234\n",
      "tensor(51.5525)\n",
      "at batch  10\n",
      "0.5605010986328125\n",
      "tensor(36.8485)\n",
      "at batch  20\n",
      "0.4876983165740967\n",
      "tensor(41.0062)\n",
      "at batch  30\n",
      "0.48968958854675293\n",
      "tensor(32.0478)\n",
      "at batch  40\n",
      "0.62233567237854\n",
      "tensor(36.9143)\n",
      "at batch  50\n",
      "0.49767088890075684\n",
      "tensor(41.2393)\n",
      "at batch  60\n",
      "0.48769688606262207\n",
      "tensor(40.0479)\n",
      "at batch  0\n",
      "0.26628708839416504\n",
      "tensor(36.7104)\n",
      "at batch  10\n",
      "0.649259090423584\n",
      "tensor(36.6444)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch  20\n",
      "0.5046532154083252\n",
      "tensor(33.9315)\n",
      "at batch  30\n",
      "0.48370862007141113\n",
      "tensor(49.5700)\n",
      "at batch  40\n",
      "0.5485367774963379\n",
      "tensor(41.3604)\n",
      "at batch  50\n",
      "0.5126328468322754\n",
      "tensor(39.2457)\n",
      "at batch  60\n",
      "0.49268364906311035\n",
      "tensor(40.1163)\n",
      "at batch  0\n",
      "0.2702760696411133\n",
      "tensor(29.7706)\n",
      "at batch  10\n",
      "0.5046508312225342\n",
      "tensor(33.6876)\n",
      "at batch  20\n",
      "0.5016610622406006\n",
      "tensor(40.9644)\n",
      "at batch  30\n",
      "0.5006616115570068\n",
      "tensor(33.9860)\n",
      "at batch  40\n",
      "0.5485343933105469\n",
      "tensor(34.4313)\n",
      "at batch  50\n",
      "0.5415422916412354\n",
      "tensor(32.4552)\n",
      "at batch  60\n",
      "0.47872018814086914\n",
      "tensor(44.7647)\n",
      "at batch  0\n",
      "0.21841740608215332\n",
      "tensor(35.5252)\n",
      "at batch  10\n",
      "0.5704758167266846\n",
      "tensor(32.5602)\n",
      "at batch  20\n",
      "0.5086398124694824\n",
      "tensor(29.9109)\n",
      "at batch  30\n",
      "0.4886937141418457\n",
      "tensor(37.0481)\n",
      "at batch  40\n",
      "0.6023895740509033\n",
      "tensor(33.5121)\n",
      "at batch  50\n",
      "0.5595049858093262\n",
      "tensor(34.2009)\n",
      "at batch  60\n",
      "0.4976685047149658\n",
      "tensor(36.6152)\n",
      "at batch  0\n",
      "0.22440314292907715\n",
      "tensor(29.9508)\n",
      "at batch  10\n",
      "0.49068140983581543\n",
      "tensor(31.2410)\n",
      "at batch  20\n",
      "0.570479154586792\n",
      "tensor(33.2938)\n",
      "at batch  30\n",
      "0.4857008457183838\n",
      "tensor(31.4424)\n",
      "at batch  40\n",
      "0.47373509407043457\n",
      "tensor(38.5376)\n",
      "at batch  50\n",
      "0.5834407806396484\n",
      "tensor(35.3211)\n",
      "at batch  60\n",
      "0.5894248485565186\n",
      "tensor(34.9890)\n",
      "at batch  0\n",
      "0.24135112762451172\n",
      "tensor(30.2683)\n",
      "at batch  10\n",
      "0.49268293380737305\n",
      "tensor(29.7709)\n",
      "at batch  20\n",
      "0.47872018814086914\n",
      "tensor(32.2021)\n",
      "at batch  30\n",
      "0.5694789886474609\n",
      "tensor(36.1460)\n",
      "at batch  40\n",
      "0.49068737030029297\n",
      "tensor(35.7256)\n",
      "at batch  50\n",
      "0.5056495666503906\n",
      "tensor(33.6265)\n",
      "at batch  60\n",
      "0.5774557590484619\n",
      "tensor(35.3127)\n",
      "at batch  0\n",
      "0.26130175590515137\n",
      "tensor(36.4208)\n",
      "at batch  10\n",
      "0.5744640827178955\n",
      "tensor(35.9164)\n",
      "at batch  20\n",
      "0.4886941909790039\n",
      "tensor(37.3169)\n",
      "at batch  30\n",
      "0.4886913299560547\n",
      "tensor(33.9477)\n",
      "at batch  40\n",
      "0.6073756217956543\n",
      "tensor(34.2843)\n",
      "at batch  50\n",
      "0.5993976593017578\n",
      "tensor(30.7720)\n",
      "at batch  60\n",
      "0.502657413482666\n",
      "tensor(32.0295)\n",
      "total time taken: 101.93151354789734\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8d88ae160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN NETWORK\n",
    "%matplotlib inline\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "use_cuda = False#torch.cuda.is_available()\n",
    "\n",
    "BSG_model = bayesian_skipgram(num_words, EMBEDDING_DIM)\n",
    "\n",
    "if use_cuda:\n",
    "    BSG_model.cuda()\n",
    "optimizer = torch.optim.Adam(BSG_model.parameters(), lr=0.005)\n",
    "BSG_model.train()\n",
    "loss_progress = []\n",
    "iter_time = time.time()\n",
    "\n",
    "dataloader = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        main_word = batch[:,0]\n",
    "        context_word = batch[:,1:]\n",
    "\n",
    "        #print(\"Main word:,\", main_word.shape, context_word.shape)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if use_cuda:\n",
    "            loss = BSG_model.forward(main_word.cuda(), context_word.cuda(), use_cuda=True)\n",
    "        else:\n",
    "            loss = BSG_model.forward(main_word, context_word)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(\"epoch, batch \", epoch, i)\n",
    "            loss_progress.append(loss.item())  \n",
    "            print(time.time()-iter_time)\n",
    "            print(loss)\n",
    "            iter_time = time.time()\n",
    "print(\"total time taken:\", time.time()-start_time)\n",
    "plt.plot(loss_progress)\n",
    "plt.savefig('plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sindi\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:193: UserWarning: Couldn't retrieve source code for container of type bayesian_skipgram. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(BSG_model, 'bayesian_skipgram.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all needed data\n",
    "\n",
    "def get_test_data(filename):\n",
    "    test_data = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.split('\\t')\n",
    "            test_word = line[0]\n",
    "            sentence_id = line[1]\n",
    "            test_data.append([test_word, sentence_id])\n",
    "    return(test_data)\n",
    "\n",
    "def get_candidates(filename):\n",
    "    with open(filename) as f:\n",
    "        candidate_dict = {}\n",
    "        for line in f:\n",
    "            line = line.split('::')\n",
    "            word = line[0]\n",
    "            candidates = line[1].split(';')\n",
    "            candidate_dict[word] = candidates\n",
    "        return candidate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "test_data = get_test_data('lst/lst_test.preprocessed')\n",
    "\n",
    "candidates = get_candidates('lst/lst.gold.candidates')\n",
    "\n",
    "with open('w2i_skipgram.pkl', 'rb') as f:\n",
    "    w2i = pickle.load(f)\n",
    "\n",
    "with open('i2w_skipgram.pkl', 'rb') as f:\n",
    "    i2w = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda: # load model with gpu (as it was trained)\n",
    "    bayesian_skipgram_model = torch.load('bayesian_skipgram.pt')\n",
    "else: # convert to cpu:\n",
    "    bayesian_skipgram_model = torch.load('bayesian_skipgram.pt',  map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing - take out any words/candidates aren't present in original corpus (w2i check)  \n",
    "orig_test_data = test_data[:]\n",
    "for [word, sentence_id] in test_data[:]:\n",
    "    word_nopos = word[:-2]\n",
    "    if word_nopos not in w2i:\n",
    "        test_data.remove([word, sentence_id])\n",
    "    for candidate in candidates[word][:]:\n",
    "        if candidate not in w2i:\n",
    "            candidates[word].remove(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words to indexes\n",
    "\n",
    "word_is = [w2i[word[:-2]] for word, _ in test_data]\n",
    "word_is = torch.LongTensor(word_is)\n",
    "\n",
    "can_is = {}\n",
    "for [word, _] in test_data[:]:\n",
    "    can_i = [w2i[can] for can in candidates[word]]\n",
    "    word_i = w2i[word[:-2]]\n",
    "    can_is[word_i] = torch.LongTensor(can_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking(word, candidates):\n",
    "\n",
    "    cos = torch.nn.CosineSimilarity(dim=0)\n",
    "    \n",
    "    if use_cuda:\n",
    "        word = word.cuda()\n",
    "\n",
    "    word_embedding = bayesian_skipgram_model.R(word)\n",
    "    can_sims = []\n",
    "    for can in candidates:\n",
    "        if use_cuda:\n",
    "            can = can.cuda()\n",
    "        can_embedding = bayesian_skipgram_model.R(can)\n",
    "        sim = cos(word_embedding, can_embedding)\n",
    "        can_sims.append([can, sim])\n",
    "            \n",
    "    can_sims = sorted(can_sims, key = lambda x: x[1])\n",
    "    return(can_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i, [word, sentence_id] in enumerate(test_data):\n",
    "    word_i = word_is[i]\n",
    "    cans = can_is[word_i.item()]\n",
    "    rank = get_ranking(word_i, cans)\n",
    "    words_scores = []\n",
    "    for [candidate, score] in rank:\n",
    "        can_word = i2w[candidate.item()]\n",
    "        score = score.item()\n",
    "        words_scores.append([can_word, score])\n",
    "    results[word] = words_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bayesian_skipgram_predictions', 'w') as f:\n",
    "    for [word, sentence_id] in orig_test_data: # lst_gap needs all words, also once we do not have data for\n",
    "        f.write('#RANKED\\t')\n",
    "        f.write(word + ' ')\n",
    "        f.write(sentence_id)\n",
    "        if word in results:\n",
    "            for [candidate, score] in results[word]:\n",
    "                f.write('\\t' + candidate + ' ' + str(score))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN_GAP\t0.06867063144654033\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8df4132e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run lst/lst_gap.py lst/lst_test.gold skipgram_predictions skipgram_out no-mwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
