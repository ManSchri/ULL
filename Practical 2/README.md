
# Learning Word Representations

This repository holds implementations and evaluations of three word embedding models: Skip-gram, Bayesian Skip-gram and EmbedAlign. 

To run any of the models go to the respective notebook Skipgram.ipynb, BayesianSkipgram.ipynb and EmbedAlign.ipynb. The training data should be within the same folder for hansards and europarl dataset. 

To evaluate, having the Lexical Substitution Task dataset in the folder, run the respective Skipgram_evaluation.ipynb, BayesianSkipgram_evaluation.ipynb and EmbedAlign_evaluation.ipynb. 


All the rest of the files can be generated from code, although it may be helpful to load pre-generated wocabulary indices.  
