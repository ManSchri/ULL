{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# read in data, remove punctuation and make all lower case\n",
    "def read_words(filename):\n",
    "    words = []\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    scount = 0\n",
    "    with open(filename) as f:\n",
    "        for s in f:\n",
    "            scount += 1\n",
    "            clean_s = s.translate(translator).lower()\n",
    "            words.append(clean_s.split())\n",
    "    return words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict that returns the index of onehot encoding for a word (and other way around)\n",
    "# also create a frequency dict + set size, usuable for negative sampling\n",
    "import numpy as np\n",
    "\n",
    "def get_onehot_dicts(corpus):\n",
    "    # create one set of all unique words\n",
    "    flat_corpus = [w for s in corpus for w in s]\n",
    "    corpus_set = set(flat_corpus)\n",
    "    w_to_i = {}\n",
    "    i_to_w = {}\n",
    "    w_freq = []\n",
    "    num_words = len(corpus_set)\n",
    "    for i, w in enumerate(corpus_set):\n",
    "        w_to_i[w] = i\n",
    "        i_to_w[i] = w\n",
    "        freq = flat_corpus.count(w)**0.75\n",
    "        w_freq.append([i, freq])\n",
    "    return w_to_i, i_to_w, np.array(w_freq), num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus created\n"
     ]
    }
   ],
   "source": [
    "#corpus = read_words('wa/test.en')\n",
    "l1_corpus = read_words('wa/dev.en')\n",
    "l2_corpus = read_words('wa/dev.fr')\n",
    "print('corpus created')\n",
    "w_to_i1, i_to_w1, w_freq1, num_words1 = get_onehot_dicts(l1_corpus)\n",
    "w_to_i2, i_to_w2, w_freq2, num_words2 = get_onehot_dicts(l2_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save w_to_i and i_to_w to files\n",
    "import pickle\n",
    "\n",
    "with open('w2i_en_embedalign.pkl', 'wb') as f:\n",
    "    pickle.dump(w_to_i1, f)\n",
    "    \n",
    "with open('i2w_en_embedalign.pkl', 'wb') as f:\n",
    "    pickle.dump(i_to_w1, f)\n",
    "    \n",
    "with open('w2i_fr_embedalign.pkl', 'wb') as f:\n",
    "    pickle.dump(w_to_i2, f)\n",
    "    \n",
    "with open('i2w_fr_embedalign.pkl', 'wb') as f:\n",
    "    pickle.dump(i_to_w2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform corpus to lists of ints\n",
    "import torch\n",
    "\n",
    "l1_corpus_i = [[w_to_i1[word] for word in sentence] for sentence in l1_corpus]\n",
    "l2_corpus_i = [[w_to_i2[word] for word in sentence] for sentence in l2_corpus]\n",
    "\n",
    "total_corpus_i = [l1_corpus_i, l2_corpus_i]\n",
    "# cannot turn into longtensor because not all sentences have same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "import torch.utils.data\n",
    "from torch.utils.data import sampler\n",
    "class embed_align(nn.Module):\n",
    "    def __init__(self, vocab_size1, vocab_size2, emb_dimension):\n",
    "        super(embed_align, self).__init__()\n",
    "        self.vocab_size1 = vocab_size1\n",
    "        self.vocab_size2 = vocab_size2\n",
    "        self.emb_dimension = emb_dimension\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size1, emb_dimension)\n",
    "        self.BiLSTM = nn.LSTM(emb_dimension, emb_dimension, bidirectional=True)\n",
    "        \n",
    "        self.affine1_mu = nn.Linear(emb_dimension, emb_dimension)\n",
    "        self.affine2_mu = nn.Linear(emb_dimension, emb_dimension)\n",
    "        \n",
    "        self.affine1_sig = nn.Linear(emb_dimension, emb_dimension)\n",
    "        self.affine2_sig = nn.Linear(emb_dimension, emb_dimension)\n",
    "        \n",
    "        self.affine1_L1 = nn.Linear(emb_dimension, emb_dimension)\n",
    "        self.affine2_L1 = nn.Linear(emb_dimension, vocab_size1)\n",
    "        self.affine1_L2 = nn.Linear(emb_dimension, emb_dimension)\n",
    "        self.affine2_L2 = nn.Linear(emb_dimension, vocab_size2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, sentence1, sentence2):\n",
    "        # sentence1 & sentence2 are (batches of) list of all ints in a sentence\n",
    "        # encoder\n",
    "        m = len(sentence1)\n",
    "        sen1_emb = self.embedding(sentence1)\n",
    "        h, _ = self.BiLSTM(sen1_emb.unsqueeze(1))\n",
    "        h1, h2 = torch.split(h, split_size_or_sections=self.emb_dimension, dim =2)\n",
    "        h = h1 + h2\n",
    "        mu = self.affine2_mu(self.relu(self.affine1_mu(h)))\n",
    "        sig = self.relu(self.affine2_sig(self.relu(self.affine1_sig(h))))\n",
    "        \n",
    "        sample_norm = dist.multivariate_normal.MultivariateNormal(torch.zeros(self.emb_dimension), torch.eye(self.emb_dimension))\n",
    "        e = sample_norm.sample()\n",
    "        z = mu + e * sig\n",
    "        # remove once generate part finished\n",
    "        z = z.squeeze(1)\n",
    "    \n",
    "        # generate\n",
    "        dist_1 = self.softmax(self.affine2_L1(self.relu(self.affine1_L1(z))))\n",
    "        dist_2 = self.softmax(self.affine2_L2(self.relu(self.affine1_L2(z))))\n",
    "\n",
    "        cat_dist_1 = dist.Categorical(dist_1)\n",
    "        cat_dist_2 = dist.Categorical(dist_2)\n",
    "        \n",
    "        x = cat_dist_1.sample()\n",
    "        y = cat_dist_2.sample()\n",
    "        \n",
    "        # compute loss\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ea_model = embed_align(num_words1, num_words2, 200)\n",
    "i_1 = [w_to_i1[w] for w in l1_corpus[0]]\n",
    "i_2 = [w_to_i2[w] for w in l2_corpus[0]]\n",
    "\n",
    "i_1 = torch.LongTensor(i_1)\n",
    "i_2 = torch.LongTensor(i_2)\n",
    "\n",
    "ea_model.forward(i_1, i_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
